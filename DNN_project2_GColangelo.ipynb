{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796244d8-0203-4c08-bc31-8afd764a1fa8",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Time series classification on Starlight curves dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17147291-393a-4f76-910f-9f60deabc08a",
   "metadata": {},
   "source": [
    "Goal of this project is to apply the most common time series classification (TSC) methods on a publicly available dataset out of Astronomy studies, namely the Starlight curves dataset, which can be downloaded <a href=\"http://www.timeseriesclassification.com/description.php?Dataset=StarlightCurves\" target=\"_blank\">here</a>.\n",
    "\n",
    "The dataset consists of N = 9236 starlight curves. The brightness of celestial objects was recorded over time in a set of n = 1024 samples. There are three types of stars: Eclipsed Binaries (purple), Cepheids (blue) and RR Lyrae Variables (green). Our goal is to classify stars based on their brightness variation over time.\n",
    "\n",
    "We used the standard train/test split but we used 10% of the training set for validation purposes. So to summarize following were the sizes of the data subsets for our experiments:\n",
    "\n",
    "| Subset | Size |\n",
    "| :--- | ---: |\n",
    "| Train | 900 |\n",
    "| Validation | 100 |\n",
    "| Test | 8236 |\n",
    "\n",
    "\n",
    "The model architectures we developed and tested were based on state-of-the-art TSC methods described in [1] and [2]. In particular, we measured classification performance of 4 different models:\n",
    "\n",
    "1. Multi-layer Perceptron (MLP) - based on the architecture described in [2]\n",
    "2. Single-layer LSTM (RNN and GRU classes are also available)\n",
    "3. CNN - based on the architecture described in [1]\n",
    "4. ResNet - based on the architecture described in [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519ad174",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94349918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device:cpu\n",
      "\n",
      "python:\n",
      "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]\n",
      "\n",
      "torch==1.11.0+cpu\n",
      "numpy==1.21.5\n",
      "tqdm==4.64.0\n",
      "matplotlib==3.5.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import tqdm as tqdm_ \n",
    "from tqdm.notebook import tqdm # Overkill progress bars\n",
    "from torchsummary import summary\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from ray import tune\n",
    "from ray.tune import CLIReporter\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"device:{}\\n\".format(device))\n",
    "print(\"python:\\n{}\\n\".format(sys.version))\n",
    "print(\"torch=={}\".format(torch.__version__))\n",
    "print(\"numpy=={}\".format(np.__version__))\n",
    "\n",
    "print(\"tqdm=={}\".format(tqdm_.__version__))\n",
    "print(\"matplotlib=={}\".format(matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840196c5",
   "metadata": {},
   "source": [
    "## Data ingestion and preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "faca44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('StarLightCurves/StarLightCurves_TRAIN.txt', header=None,delim_whitespace=True)\n",
    "df_test = pd.read_csv('StarLightCurves/StarLightCurves_TEST.txt', header=None, delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d6310d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "      <th>1024</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.537303</td>\n",
       "      <td>0.531103</td>\n",
       "      <td>0.528503</td>\n",
       "      <td>0.529403</td>\n",
       "      <td>0.533603</td>\n",
       "      <td>0.540903</td>\n",
       "      <td>0.551103</td>\n",
       "      <td>0.564003</td>\n",
       "      <td>0.579603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.547103</td>\n",
       "      <td>0.546903</td>\n",
       "      <td>0.545903</td>\n",
       "      <td>0.543903</td>\n",
       "      <td>0.541003</td>\n",
       "      <td>0.537203</td>\n",
       "      <td>0.532303</td>\n",
       "      <td>0.526403</td>\n",
       "      <td>0.519503</td>\n",
       "      <td>0.511403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.588398</td>\n",
       "      <td>0.593898</td>\n",
       "      <td>0.599098</td>\n",
       "      <td>0.604098</td>\n",
       "      <td>0.608798</td>\n",
       "      <td>0.613397</td>\n",
       "      <td>0.617797</td>\n",
       "      <td>0.622097</td>\n",
       "      <td>0.626097</td>\n",
       "      <td>...</td>\n",
       "      <td>0.228799</td>\n",
       "      <td>0.237399</td>\n",
       "      <td>0.246499</td>\n",
       "      <td>0.256199</td>\n",
       "      <td>0.266499</td>\n",
       "      <td>0.277399</td>\n",
       "      <td>0.288799</td>\n",
       "      <td>0.300899</td>\n",
       "      <td>0.313599</td>\n",
       "      <td>0.326899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.049900</td>\n",
       "      <td>-0.041500</td>\n",
       "      <td>-0.033400</td>\n",
       "      <td>-0.025600</td>\n",
       "      <td>-0.018100</td>\n",
       "      <td>-0.010800</td>\n",
       "      <td>-0.003800</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.185601</td>\n",
       "      <td>-0.173801</td>\n",
       "      <td>-0.161601</td>\n",
       "      <td>-0.149201</td>\n",
       "      <td>-0.136401</td>\n",
       "      <td>-0.123201</td>\n",
       "      <td>-0.109701</td>\n",
       "      <td>-0.095901</td>\n",
       "      <td>-0.081701</td>\n",
       "      <td>-0.067100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.337005</td>\n",
       "      <td>1.319805</td>\n",
       "      <td>1.302905</td>\n",
       "      <td>1.286305</td>\n",
       "      <td>1.270005</td>\n",
       "      <td>1.254005</td>\n",
       "      <td>1.238304</td>\n",
       "      <td>1.223005</td>\n",
       "      <td>1.208104</td>\n",
       "      <td>...</td>\n",
       "      <td>1.278905</td>\n",
       "      <td>1.288905</td>\n",
       "      <td>1.298505</td>\n",
       "      <td>1.307705</td>\n",
       "      <td>1.316505</td>\n",
       "      <td>1.324905</td>\n",
       "      <td>1.332805</td>\n",
       "      <td>1.340205</td>\n",
       "      <td>1.347005</td>\n",
       "      <td>1.353205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.769801</td>\n",
       "      <td>0.775301</td>\n",
       "      <td>0.780401</td>\n",
       "      <td>0.785101</td>\n",
       "      <td>0.789401</td>\n",
       "      <td>0.793301</td>\n",
       "      <td>0.796801</td>\n",
       "      <td>0.799901</td>\n",
       "      <td>0.802601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.740801</td>\n",
       "      <td>0.742401</td>\n",
       "      <td>0.744501</td>\n",
       "      <td>0.747301</td>\n",
       "      <td>0.750701</td>\n",
       "      <td>0.754801</td>\n",
       "      <td>0.759501</td>\n",
       "      <td>0.765001</td>\n",
       "      <td>0.771301</td>\n",
       "      <td>0.778401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.751000</td>\n",
       "      <td>-0.749100</td>\n",
       "      <td>-0.747100</td>\n",
       "      <td>-0.745200</td>\n",
       "      <td>-0.743300</td>\n",
       "      <td>-0.741500</td>\n",
       "      <td>-0.739600</td>\n",
       "      <td>-0.737800</td>\n",
       "      <td>-0.735900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.770900</td>\n",
       "      <td>-0.768600</td>\n",
       "      <td>-0.766100</td>\n",
       "      <td>-0.763500</td>\n",
       "      <td>-0.760700</td>\n",
       "      <td>-0.757800</td>\n",
       "      <td>-0.754700</td>\n",
       "      <td>-0.751500</td>\n",
       "      <td>-0.748100</td>\n",
       "      <td>-0.744600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.867600</td>\n",
       "      <td>0.860300</td>\n",
       "      <td>0.853300</td>\n",
       "      <td>0.846500</td>\n",
       "      <td>0.840100</td>\n",
       "      <td>0.834000</td>\n",
       "      <td>0.828100</td>\n",
       "      <td>0.822600</td>\n",
       "      <td>0.817400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.845200</td>\n",
       "      <td>0.847500</td>\n",
       "      <td>0.849800</td>\n",
       "      <td>0.852100</td>\n",
       "      <td>0.854400</td>\n",
       "      <td>0.856800</td>\n",
       "      <td>0.859200</td>\n",
       "      <td>0.861700</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.866600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.087398</td>\n",
       "      <td>0.097398</td>\n",
       "      <td>0.107698</td>\n",
       "      <td>0.118298</td>\n",
       "      <td>0.129298</td>\n",
       "      <td>0.140398</td>\n",
       "      <td>0.151898</td>\n",
       "      <td>0.163498</td>\n",
       "      <td>0.175398</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0.012198</td>\n",
       "      <td>0.022098</td>\n",
       "      <td>0.032398</td>\n",
       "      <td>0.042898</td>\n",
       "      <td>0.053798</td>\n",
       "      <td>0.065098</td>\n",
       "      <td>0.076698</td>\n",
       "      <td>0.088698</td>\n",
       "      <td>0.101098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.664799</td>\n",
       "      <td>0.654799</td>\n",
       "      <td>0.646099</td>\n",
       "      <td>0.638599</td>\n",
       "      <td>0.632299</td>\n",
       "      <td>0.627199</td>\n",
       "      <td>0.623099</td>\n",
       "      <td>0.619999</td>\n",
       "      <td>0.617899</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699199</td>\n",
       "      <td>0.699299</td>\n",
       "      <td>0.698899</td>\n",
       "      <td>0.698099</td>\n",
       "      <td>0.696899</td>\n",
       "      <td>0.695299</td>\n",
       "      <td>0.693299</td>\n",
       "      <td>0.690799</td>\n",
       "      <td>0.687799</td>\n",
       "      <td>0.684399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.563602</td>\n",
       "      <td>0.569502</td>\n",
       "      <td>0.574902</td>\n",
       "      <td>0.579702</td>\n",
       "      <td>0.583902</td>\n",
       "      <td>0.587702</td>\n",
       "      <td>0.591002</td>\n",
       "      <td>0.593802</td>\n",
       "      <td>0.596202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.151901</td>\n",
       "      <td>0.176101</td>\n",
       "      <td>0.203402</td>\n",
       "      <td>0.233902</td>\n",
       "      <td>0.267602</td>\n",
       "      <td>0.304802</td>\n",
       "      <td>0.345602</td>\n",
       "      <td>0.390102</td>\n",
       "      <td>0.438302</td>\n",
       "      <td>0.490602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 1025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1         2         3         4         5         6     \\\n",
       "0     3.0  0.537303  0.531103  0.528503  0.529403  0.533603  0.540903   \n",
       "1     3.0  0.588398  0.593898  0.599098  0.604098  0.608798  0.613397   \n",
       "2     1.0 -0.049900 -0.041500 -0.033400 -0.025600 -0.018100 -0.010800   \n",
       "3     3.0  1.337005  1.319805  1.302905  1.286305  1.270005  1.254005   \n",
       "4     3.0  0.769801  0.775301  0.780401  0.785101  0.789401  0.793301   \n",
       "..    ...       ...       ...       ...       ...       ...       ...   \n",
       "995   2.0 -0.751000 -0.749100 -0.747100 -0.745200 -0.743300 -0.741500   \n",
       "996   3.0  0.867600  0.860300  0.853300  0.846500  0.840100  0.834000   \n",
       "997   1.0  0.087398  0.097398  0.107698  0.118298  0.129298  0.140398   \n",
       "998   3.0  0.664799  0.654799  0.646099  0.638599  0.632299  0.627199   \n",
       "999   3.0  0.563602  0.569502  0.574902  0.579702  0.583902  0.587702   \n",
       "\n",
       "         7         8         9     ...      1015      1016      1017  \\\n",
       "0    0.551103  0.564003  0.579603  ...  0.547103  0.546903  0.545903   \n",
       "1    0.617797  0.622097  0.626097  ...  0.228799  0.237399  0.246499   \n",
       "2   -0.003800  0.003000  0.009600  ... -0.185601 -0.173801 -0.161601   \n",
       "3    1.238304  1.223005  1.208104  ...  1.278905  1.288905  1.298505   \n",
       "4    0.796801  0.799901  0.802601  ...  0.740801  0.742401  0.744501   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "995 -0.739600 -0.737800 -0.735900  ... -0.770900 -0.768600 -0.766100   \n",
       "996  0.828100  0.822600  0.817400  ...  0.845200  0.847500  0.849800   \n",
       "997  0.151898  0.163498  0.175398  ...  0.002598  0.012198  0.022098   \n",
       "998  0.623099  0.619999  0.617899  ...  0.699199  0.699299  0.698899   \n",
       "999  0.591002  0.593802  0.596202  ...  0.151901  0.176101  0.203402   \n",
       "\n",
       "         1018      1019      1020      1021      1022      1023      1024  \n",
       "0    0.543903  0.541003  0.537203  0.532303  0.526403  0.519503  0.511403  \n",
       "1    0.256199  0.266499  0.277399  0.288799  0.300899  0.313599  0.326899  \n",
       "2   -0.149201 -0.136401 -0.123201 -0.109701 -0.095901 -0.081701 -0.067100  \n",
       "3    1.307705  1.316505  1.324905  1.332805  1.340205  1.347005  1.353205  \n",
       "4    0.747301  0.750701  0.754801  0.759501  0.765001  0.771301  0.778401  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "995 -0.763500 -0.760700 -0.757800 -0.754700 -0.751500 -0.748100 -0.744600  \n",
       "996  0.852100  0.854400  0.856800  0.859200  0.861700  0.864100  0.866600  \n",
       "997  0.032398  0.042898  0.053798  0.065098  0.076698  0.088698  0.101098  \n",
       "998  0.698099  0.696899  0.695299  0.693299  0.690799  0.687799  0.684399  \n",
       "999  0.233902  0.267602  0.304802  0.345602  0.390102  0.438302  0.490602  \n",
       "\n",
       "[1000 rows x 1025 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65eb6ce",
   "metadata": {},
   "source": [
    "We store the sequence length that is going to be used for data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78477ba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length=df_train.iloc[:,1:].shape[1]\n",
    "seq_length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec520b3a",
   "metadata": {},
   "source": [
    "We prepare the set according to the shape train/test size, sequence length (24) and feature size i.e. 1 for univariate TS. This is the format required by RNN models. For the other models we need then to switch the format to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f01d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.iloc[:, 1:].values.reshape(-1,seq_length,1)\n",
    "X_test = df_test.iloc[:, 1:].values.reshape(-1,seq_length,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dc5a48",
   "metadata": {},
   "source": [
    "We modify the labels to be 0, 1 and 2 instead of 1, 2 and 3 because our CrossEntropyLoss criterion requires classes indices to be in the range [0, C) where C is the number of classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ba5b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train.iloc[:, 0].values-1\n",
    "y_test = df_test.iloc[:, 0].values-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eaa49c8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 2., ..., 0., 1., 2.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99498c44",
   "metadata": {},
   "source": [
    "We split the training set so that 10% of the data are dedicated to validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f14562b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.arange(len(X_train))\n",
    "train_idx, val_idx = train_test_split(idx, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2488e6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(torch.tensor(X_train[train_idx]).float(),torch.tensor(y_train[train_idx]).long())\n",
    "val_ds = TensorDataset(torch.tensor(X_train[val_idx]).float(),torch.tensor(y_train[val_idx]).long())\n",
    "test_ds = TensorDataset(torch.tensor(X_test).float(),torch.tensor(y_test).long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c535668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.53730293, 0.53110294, 0.52850294, ..., 0.52640294, 0.51950294,\n",
       "       0.51140294])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b8aac63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1024, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec21dfb",
   "metadata": {},
   "source": [
    "We choose a **batch size** equal to 50. Given the **number of epochs** that we later set to 100, it will take 18 iterations to pass the entire training dataset made of 900 sequences to pass through the models. \n",
    "\n",
    "We could adapt these parameters depending on how the losses are changing as a function of the epochs. If we see that training is  completed, while the losses are still going down, this is probably an indication of underfitting and we could increase the number of epochs. On the contrary, if the losses are stabilizing or even increasing, then we are most likely overfitting.\n",
    "\n",
    "We will see later how our traning process is behaving using these initial values for these parameters.\n",
    "\n",
    "Actually a necessary step that we have not covered in this notebook is cross-validation. Optimal values of batch size and learning rate should typically be found in a cross-validation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49bade69",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "706c16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_ds,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False, drop_last = True)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_ds,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False, drop_last = True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_ds,\n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=False, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f88365",
   "metadata": {},
   "source": [
    "Plot brightness samples of the three different star types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d449cbd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2a4c1589dc0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(0,71,35): \n",
    "    plt.plot(X_train[:,:,0][i],label=\"sample={}, target={}\".format(i, y_train[i]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2567f3",
   "metadata": {},
   "source": [
    "## Models definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509310d6-8791-49ce-8872-b328e7690577",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edda1382",
   "metadata": {},
   "source": [
    "The architecture described in [2] and represented in the figure below is implemented here. Note that eventually we removed the final softmax layer from the code because, when further studying the **CrossEntropyLoss** criterion documentation, we found out that the criterion combines  already a LogSoftMax operation together with NLLLoss. So applying it in the architecture would mean using it twice. In fact, when commenting out the SoftMax layer, performance classification increased significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccc08d5",
   "metadata": {},
   "source": [
    "![Image file needs to be placed in the same working directory of the .ipynb](MLP.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88e0389f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPModel (nn.Module):\n",
    "    def __init__(self, seq_length, hidden_size, n_classes, drop_prob):\n",
    "        super().__init__()\n",
    "        self.input_size = seq_length\n",
    "        self.hidden_size  = hidden_size\n",
    "        self.dropout = nn.Dropout(drop_prob)        \n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(drop_prob*2)\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(drop_prob*2)\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(self.hidden_size, n_classes)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.dropout3 = nn.Dropout(drop_prob*3)\n",
    "        \n",
    "        #self.softmax = torch.nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        hidden1 = self.dropout1(self.relu1(self.fc1(x)))\n",
    "        hidden2 = self.dropout2(self.relu2(self.fc2(hidden1)))\n",
    "        output = self.dropout3(self.relu3(self.fc3(hidden2)))\n",
    "        prediction = output\n",
    "        return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143405f7-3413-4208-b5ea-6169fdf57956",
   "metadata": {},
   "source": [
    "### RNN, LSTM, GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "836194a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNModel (nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, n_classes=3, drop_prob=0): #input_size = number of features that in our case of univariate TS is equal to 1.\n",
    "        super(RNNModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers    \n",
    "        self.rnn = nn.RNN(input_size,hidden_size,n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_size, n_classes)\n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, inputs): #Input is a tensor with shape 24x1 in other words seq_length 24 x 1 feature. However I need to add batch_size first.\n",
    "        #Initialization of state = h_0\n",
    "        h_0 = torch.zeros(self.n_layers, inputs.size(0), self.hidden_size, device=device).requires_grad_()\n",
    "        h_t, state = self.rnn(inputs)\n",
    "        output = self.fc(h_t[:,-1,:]) #We take only the last element of the sequence h_t to make a prediction\n",
    "        prediction = self.softmax(output)\n",
    "        return prediction        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e1fbd2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel (nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, n_classes=3, drop_prob=0): #input_size = number of features that in our case of univariate TS is equal to 1.\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers    \n",
    "        self.lstm = nn.LSTM(input_size,hidden_size,n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_size, n_classes)\n",
    "        #self.softmax = torch.nn.Softmax(dim=0)\n",
    "        #self.tanh = nn.Tanh()\n",
    "    \n",
    "    def forward(self, inputs): #Input is a tensor with shape 24x1 in other words seq_length 24 x 1 feature. However I need to add batch_size first.\n",
    "        #Initialization of state = h_0, c_0\n",
    "        state = (torch.zeros(self.n_layers, inputs.size(0), self.hidden_size, device=device).requires_grad_(),\n",
    "                torch.zeros(self.n_layers, inputs.size(0), self.hidden_size, device=device).requires_grad_())\n",
    "        h_t, state = self.lstm(inputs, state)\n",
    "        output = self.fc(h_t[:,-1,:]) #We take only the last element of the sequence h_t to make a prediction\n",
    "        #prediction = self.softmax(output)\n",
    "        return output        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "76d14984",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel (nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, n_classes=3, drop_prob=0): #input_size = number of features that in our case of univariate TS is equal to 1.\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers    \n",
    "        self.gru = nn.GRU(input_size,hidden_size,n_layers, dropout=drop_prob, batch_first=True)\n",
    "        self.fc=nn.Linear(hidden_size, n_classes)\n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "    \n",
    "    def forward(self, inputs): #Input is a tensor with shape 24x1 in other words seq_length 24 x 1 feature. However I need to add batch_size first.\n",
    "        #Initialization of state = h_0\n",
    "        h_0 = torch.zeros(self.n_layers, inputs.size(0), self.hidden_size, device=device)\n",
    "        h_t, state = self.gru(inputs)\n",
    "        output = self.fc(h_t[:,-1,:]) #We take only the last element of the sequence h_t to make a prediction\n",
    "        prediction = self.softmax(output)\n",
    "        return prediction        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67e8868",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f813ce",
   "metadata": {},
   "source": [
    "The architecture we select is suggested in [1] and represented in the figure below with the difference that we apply it to our univariate time-series. \n",
    "\n",
    "It consists of two convolutional layers, each followed by a max pooling operation. Data are finally passed through two fully connected linear layers that eventually reduce the connections to the number of classes for the final classification. \n",
    "\n",
    "Important design parameters for the architecture are the number of convolutional filters together with their size in the initial two layers. In the final linear layers it is important then to decide how many nodes are used in the hidden layer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60180a0",
   "metadata": {},
   "source": [
    "![Image file needs to be placed in the same working directory of the .ipynb](CNN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e901f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNModel(nn.Module):\n",
    "    def __init__(self, conv_filters, conv_filters2, conv_filter_size, num_units_fc):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.num_inputs_fc = conv_filters2*(int(((seq_length-conv_filter_size+1)/2-conv_filter_size+1)/2))\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels = 1, out_channels = conv_filters, \n",
    "                               kernel_size=conv_filter_size, padding = 0, stride = 1)\n",
    "        self.max_pool = nn.MaxPool1d(2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels = conv_filters, out_channels = conv_filters2, \n",
    "                               kernel_size=conv_filter_size, padding = 0, stride = 1)\n",
    "        self.max_pool2 = nn.MaxPool1d(2)\n",
    "        self.fc = nn.Linear(self.num_inputs_fc, num_units_fc)\n",
    "        self.out = nn.Linear(num_units_fc, n_classes) \n",
    "\n",
    "    def forward(self, x):\n",
    "        #set_trace()\n",
    "        x = x.view(-1, 1, seq_length)\n",
    "        x = self.conv1(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.max_pool2(x)\n",
    "        x = x.view(-1, self.num_inputs_fc)\n",
    "        x = torch.relu(self.fc(x))\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5791e85-d99d-41a4-a121-988a53573068",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707b0cc9",
   "metadata": {},
   "source": [
    "The ResNet architecture implemented here is based on the one suggested in [2] and represented in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17efe681",
   "metadata": {},
   "source": [
    "![Image file needs to be placed in the same working directory of the .ipynb](ResNet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99583d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kss=[7, 5, 3], stride=1, padding=3):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        self.convblock1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, \n",
    "                               kernel_size=kss[0], padding = 3, stride = 1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()    \n",
    "        )\n",
    "\n",
    "        self.convblock2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels, out_channels, \n",
    "                               kernel_size=kss[1], padding = 2, stride = 1),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU()    \n",
    "        )\n",
    "\n",
    "        self.convblock3 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels, out_channels, \n",
    "                               kernel_size=kss[2], padding = 1, stride = 1),\n",
    "            nn.BatchNorm1d(out_channels), \n",
    "            nn.ReLU() \n",
    "        )\n",
    "\n",
    "\n",
    "        #expand channels for the sum if necessary\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1,stride=1),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()                \n",
    "\n",
    "        self.act = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        res = x\n",
    "        x = self.convblock1(x)\n",
    "        x = self.convblock2(x)\n",
    "        x = self.convblock3(x)\n",
    "        x = x + self.shortcut(res)\n",
    "        x = self.act(x)\n",
    "        return x\n",
    "    \n",
    "class ResNetModel(nn.Module):\n",
    "    def __init__(self, in_channels, mid_channels, num_pred_classes):\n",
    "        super(ResNetModel, self).__init__()        \n",
    "        kss=[7, 5, 3]        \n",
    "        self.resblock1 = ResBlock(in_channels, mid_channels, kss=kss)\n",
    "        self.resblock2 = ResBlock(mid_channels, mid_channels * 2, kss=kss)\n",
    "        self.resblock3 = ResBlock(mid_channels * 2, mid_channels * 2, kss=kss)\n",
    "        print (self.resblock3)\n",
    "        self.gap = nn.AdaptiveAvgPool1d(1)\n",
    "        print (self.gap)\n",
    "        self.fc = nn.Linear(mid_channels * 2, num_pred_classes)\n",
    "        self.softmax = torch.nn.Softmax(dim=1) \n",
    "        print (self.fc)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 1, seq_length)\n",
    "        x = self.resblock1(x)        \n",
    "        x = self.resblock2(x)\n",
    "        x = self.resblock3(x)\n",
    "        x = self.gap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62eb8ddf-01ae-4189-99db-edde82996147",
   "metadata": {},
   "source": [
    "## Optimization class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02918810",
   "metadata": {},
   "source": [
    "Below is the optimization class that we use for hyperparameter optimization of the models described above. \n",
    "\n",
    "It is split into 4 functions: the \"train\" function that goes through over the train and validation data \"n_epochs\" times. For every batch an optimization step is applied and validated over the validation set (\"train_step\" function). In this step data are passed through the model, loss is measured, gradients are computed through backpropagation and finally parameters are updated.\n",
    "\n",
    "Losses are plotted with the help of the \"plot_losses\" function. \n",
    "\n",
    "Finally, the \"evaluate\" function measures the performance of the model over train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "891e888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "    \n",
    "    def train_step(self, x, y):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Makes predictions\n",
    "        yhat = self.model(x)\n",
    "\n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(yhat, y)\n",
    "\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        return loss.item()\n",
    "    \n",
    "    def train(self, train_loader, val_loader, batch_size=5, n_epochs=100, n_features=1):\n",
    "        \n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            batch_losses = []\n",
    "            for x_batch, y_batch in train_loader:\n",
    "                x_batch = x_batch.view([batch_size, -1, n_features]).to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                loss = self.train_step(x_batch, y_batch)\n",
    "                batch_losses.append(loss)\n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, n_features]).to(device)\n",
    "                    y_val = y_val.to(device)\n",
    "                    self.model.eval()\n",
    "                    yhat = self.model(x_val)\n",
    "                    val_loss = self.loss_fn(yhat, y_val).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(validation_loss)\n",
    "\n",
    "            if (epoch <= 10) | (epoch % 50 == 0):\n",
    "                print(\n",
    "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "                )\n",
    "\n",
    "        \n",
    "    def plot_losses(self):\n",
    "        plt.plot(self.train_losses, label=\"Training loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "        plt.legend()\n",
    "        plt.title(\"Losses\")\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "        \n",
    "    def evaluate(self, test_loader, batch_size=5, n_features=1):\n",
    "        with torch.no_grad():\n",
    "            predictions = []\n",
    "            values = []\n",
    "            total = 0\n",
    "            correct = 0\n",
    "            for x_test, y_test in test_loader:\n",
    "                x_test = x_test.view([batch_size, -1, n_features]).to(device)\n",
    "                y_test = y_test.to(device)\n",
    "                self.model.eval()\n",
    "                yhat = self.model(x_test)\n",
    "                _, predicted = torch.max(yhat.data, 1)\n",
    "                predictions.append(predicted.cpu().detach().numpy())\n",
    "                values.append(y_test.cpu().detach().numpy())\n",
    "                total += y_test.size(0)\n",
    "                correct += (predicted == y_test).sum().item()   \n",
    "        print (\"Accuracy of \", self.model, \" : %.2f %%\" % (100 * correct / total))\n",
    "        print (\"Correct : \", correct, \"Total : \", total)\n",
    "        return predictions, values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d94ab547-fc05-4908-84f1-ea27b44d3db2",
   "metadata": {},
   "source": [
    "## Execution preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e4299",
   "metadata": {},
   "source": [
    "Function to select one of the classes/models above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62842c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model, model_params):\n",
    "    models = {\n",
    "        \"mlp\" : MLPModel,\n",
    "        \"rnn\": RNNModel,\n",
    "        \"lstm\": LSTMModel,\n",
    "        \"gru\": GRUModel,\n",
    "        \"cnn\" : CNNModel,\n",
    "        \"resnet\" : ResNetModel        \n",
    "    }\n",
    "    return models.get(model.lower())(**model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f0fddb",
   "metadata": {},
   "source": [
    "Parameters setting used for all the models. We choose to have 100 epochs and a **learning rate** equal to 0.00001. This a quite low learning rate that implies a low convergence of the weights and that requires a not so low number of epochs. We use as well a very low **weight decay** in our optimizer that should help regularization.\n",
    "\n",
    "Parameters like learning rate, batch size, weight decay should actually be optimized through a **tuning** process. With the help of the ray-tuner package, we set this up for the case of MLP. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255c3847-61ec-4cf5-9637-2788f0e84513",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train.shape[-1]\n",
    "n_classes=len(np.unique(y_train))\n",
    "n_epochs = 100\n",
    "learning_rate = 1e-3\n",
    "weight_decay = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d237efa2-fd6b-4b6f-a5c5-177ae6946578",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([152, 275, 573]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "416b0dab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2.]), array([1177, 2305, 4754]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_test, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62acfbcc",
   "metadata": {},
   "source": [
    "## Hyper-parameter tuning for MLP using Ray Tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba94d16",
   "metadata": {},
   "source": [
    "Here we re-use most of the code found on the ray tune tutorial pages with only few adaptations. However, this implies a duplication of certain functions like the train and evaluate functions. Better integration of the ray-tune code with the existing train and evaluate functions would actually be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a670b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(config, checkpoint_dir=None, data_dir=None):\n",
    "\n",
    "    model_params = {\n",
    "                'seq_length': seq_length,\n",
    "                'hidden_size' : config[\"hidden_size\"],\n",
    "                'n_classes' : 3,\n",
    "                'drop_prob' : 0.1   \n",
    "               }\n",
    "\n",
    "    model = get_model('mlp', model_params)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if torch.cuda.device_count() > 1:\n",
    "            model = nn.DataParallel(model)\n",
    "    model.to(device)  \n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "    if checkpoint_dir:\n",
    "        model_state, optimizer_state = torch.load(\n",
    "            os.path.join(checkpoint_dir, \"checkpoint\"))\n",
    "        model.load_state_dict(model_state)\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    trainloader = torch.utils.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "    valloader = torch.utils.data.DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=int(config[\"batch_size\"]),\n",
    "        shuffle=True,\n",
    "        num_workers=8)\n",
    "\n",
    "    for epoch in range(100):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\"[%d, %5d] loss: %.3f\" % (epoch + 1, i + 1,\n",
    "                                                running_loss / epoch_steps))\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        for i, data in enumerate(valloader, 0):\n",
    "            with torch.no_grad():\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.cpu().numpy()\n",
    "                val_steps += 1\n",
    "\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, \"checkpoint\")\n",
    "            torch.save((model.state_dict(), optimizer.state_dict()), path)\n",
    "\n",
    "        tune.report(loss=(val_loss / val_steps), accuracy=correct / total)\n",
    "    print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "905f6948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(net, device=\"cpu\"):\n",
    "    \n",
    "    testloader = torch.utils.data.DataLoader(\n",
    "        test_ds, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1389da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(num_samples=10, max_num_epochs=10, gpus_per_trial=2):\n",
    "    data_dir = os.path.abspath(\"/home/jovyan/shared-data/\")\n",
    "    config = {\n",
    "        \"lr\": tune.choice([1e-5, 1e-3,1e-1]),        \n",
    "        \"hidden_size\": tune.choice([200,350,500]),\n",
    "        \"batch_size\": tune.choice([10, 50, 100])\n",
    "    }\n",
    "    scheduler = ASHAScheduler(\n",
    "        metric=\"loss\",\n",
    "        mode=\"min\",\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2)\n",
    "    reporter = CLIReporter(\n",
    "        # parameter_columns=[\"l1\", \"l2\", \"lr\", \"batch_size\"],\n",
    "        metric_columns=[\"loss\", \"accuracy\", \"training_iteration\"])\n",
    "    result = tune.run(\n",
    "        partial(train, data_dir=data_dir),\n",
    "        resources_per_trial={\"cpu\": 2, \"gpu\": gpus_per_trial},\n",
    "        config=config,\n",
    "        num_samples=num_samples,\n",
    "        scheduler=scheduler,\n",
    "        progress_reporter=reporter)\n",
    "\n",
    "    best_trial = result.get_best_trial(\"loss\", \"min\", \"last\")\n",
    "    print(\"Best trial config: {}\".format(best_trial.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_trial.last_result[\"loss\"]))\n",
    "    print(\"Best trial final validation accuracy: {}\".format(\n",
    "        best_trial.last_result[\"accuracy\"]))\n",
    "\n",
    "    best_trained_model = MLPModel(seq_length,best_trial.config[\"hidden_size\"],n_classes,drop_prob=0.1)\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda:0\"\n",
    "        if gpus_per_trial > 1:\n",
    "            best_trained_model = nn.DataParallel(best_trained_model)\n",
    "    best_trained_model.to(device)\n",
    "\n",
    "    best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    model_state, optimizer_state = torch.load(os.path.join(\n",
    "        best_checkpoint_dir, \"checkpoint\"))\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    test_acc = test_accuracy(best_trained_model, device)\n",
    "    print(\"Best trial test set accuracy: {}\".format(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7e23221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:16:35,793\tINFO trial_runner.py:803 -- starting train_980e3_00000\n",
      "2022-04-29 13:16:35,951\tERROR syncer.py:119 -- Log sync requires rsync to be installed.\n",
      "2022-04-29 13:16:42,533\tINFO trial_runner.py:803 -- starting train_980e3_00001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-04-29 13:16:35 (running for 00:00:00.84)\n",
      "Memory usage on this node: 40.8/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 2.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+-------------------+----------+----------------+--------------+---------------+-------+\n",
      "| Trial name        | status   | loc            |   batch_size |   hidden_size |    lr |\n",
      "|-------------------+----------+----------------+--------------+---------------+-------|\n",
      "| train_980e3_00000 | RUNNING  | 10.1.0.103:501 |           50 |           350 | 1e-05 |\n",
      "| train_980e3_00001 | PENDING  |                |           10 |           350 | 0.001 |\n",
      "| train_980e3_00002 | PENDING  |                |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00003 | PENDING  |                |           50 |           350 | 0.001 |\n",
      "| train_980e3_00004 | PENDING  |                |           10 |           350 | 0.1   |\n",
      "| train_980e3_00005 | PENDING  |                |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00006 | PENDING  |                |          100 |           350 | 0.001 |\n",
      "| train_980e3_00007 | PENDING  |                |          100 |           200 | 0.1   |\n",
      "| train_980e3_00008 | PENDING  |                |           10 |           200 | 0.1   |\n",
      "| train_980e3_00009 | PENDING  |                |          100 |           350 | 1e-05 |\n",
      "+-------------------+----------+----------------+--------------+---------------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:16:49,140\tINFO trial_runner.py:803 -- starting train_980e3_00002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-04-29 13:16:42 (running for 00:00:07.45)\n",
      "Memory usage on this node: 41.1/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 4.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (8 PENDING, 2 RUNNING)\n",
      "+-------------------+----------+----------------+--------------+---------------+-------+\n",
      "| Trial name        | status   | loc            |   batch_size |   hidden_size |    lr |\n",
      "|-------------------+----------+----------------+--------------+---------------+-------|\n",
      "| train_980e3_00000 | RUNNING  | 10.1.0.103:501 |           50 |           350 | 1e-05 |\n",
      "| train_980e3_00001 | RUNNING  | 10.1.0.103:536 |           10 |           350 | 0.001 |\n",
      "| train_980e3_00002 | PENDING  |                |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00003 | PENDING  |                |           50 |           350 | 0.001 |\n",
      "| train_980e3_00004 | PENDING  |                |           10 |           350 | 0.1   |\n",
      "| train_980e3_00005 | PENDING  |                |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00006 | PENDING  |                |          100 |           350 | 0.001 |\n",
      "| train_980e3_00007 | PENDING  |                |          100 |           200 | 0.1   |\n",
      "| train_980e3_00008 | PENDING  |                |           10 |           200 | 0.1   |\n",
      "| train_980e3_00009 | PENDING  |                |          100 |           350 | 1e-05 |\n",
      "+-------------------+----------+----------------+--------------+---------------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:16:55,730\tINFO trial_runner.py:803 -- starting train_980e3_00003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-04-29 13:16:49 (running for 00:00:14.07)\n",
      "Memory usage on this node: 41.5/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 6.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (7 PENDING, 3 RUNNING)\n",
      "+-------------------+----------+----------------+--------------+---------------+-------+\n",
      "| Trial name        | status   | loc            |   batch_size |   hidden_size |    lr |\n",
      "|-------------------+----------+----------------+--------------+---------------+-------|\n",
      "| train_980e3_00000 | RUNNING  | 10.1.0.103:501 |           50 |           350 | 1e-05 |\n",
      "| train_980e3_00001 | RUNNING  | 10.1.0.103:536 |           10 |           350 | 0.001 |\n",
      "| train_980e3_00002 | RUNNING  | 10.1.0.103:798 |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00003 | PENDING  |                |           50 |           350 | 0.001 |\n",
      "| train_980e3_00004 | PENDING  |                |           10 |           350 | 0.1   |\n",
      "| train_980e3_00005 | PENDING  |                |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00006 | PENDING  |                |          100 |           350 | 0.001 |\n",
      "| train_980e3_00007 | PENDING  |                |          100 |           200 | 0.1   |\n",
      "| train_980e3_00008 | PENDING  |                |           10 |           200 | 0.1   |\n",
      "| train_980e3_00009 | PENDING  |                |          100 |           350 | 1e-05 |\n",
      "+-------------------+----------+----------------+--------------+---------------+-------+\n",
      "\n",
      "\n",
      "== Status ==\n",
      "Current time: 2022-04-29 13:16:55 (running for 00:00:20.65)\n",
      "Memory usage on this node: 41.8/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (6 PENDING, 4 RUNNING)\n",
      "+-------------------+----------+-----------------+--------------+---------------+-------+\n",
      "| Trial name        | status   | loc             |   batch_size |   hidden_size |    lr |\n",
      "|-------------------+----------+-----------------+--------------+---------------+-------|\n",
      "| train_980e3_00000 | RUNNING  | 10.1.0.103:501  |           50 |           350 | 1e-05 |\n",
      "| train_980e3_00001 | RUNNING  | 10.1.0.103:536  |           10 |           350 | 0.001 |\n",
      "| train_980e3_00002 | RUNNING  | 10.1.0.103:798  |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00003 | RUNNING  | 10.1.0.103:1074 |           50 |           350 | 0.001 |\n",
      "| train_980e3_00004 | PENDING  |                 |           10 |           350 | 0.1   |\n",
      "| train_980e3_00005 | PENDING  |                 |           50 |           500 | 1e-05 |\n",
      "| train_980e3_00006 | PENDING  |                 |          100 |           350 | 0.001 |\n",
      "| train_980e3_00007 | PENDING  |                 |          100 |           200 | 0.1   |\n",
      "| train_980e3_00008 | PENDING  |                 |           10 |           200 | 0.1   |\n",
      "| train_980e3_00009 | PENDING  |                 |          100 |           350 | 1e-05 |\n",
      "+-------------------+----------+-----------------+--------------+---------------+-------+\n",
      "\n",
      "\n",
      "Result for train_980e3_00002:\n",
      "  accuracy: 0.66\n",
      "  date: 2022-04-29_13-16-56\n",
      "  done: false\n",
      "  experiment_id: 92e1accef7de4c249b38d5b360832e38\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.5840206146240234\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 798\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6887288093566895\n",
      "  time_this_iter_s: 0.6887288093566895\n",
      "  time_total_s: 0.6887288093566895\n",
      "  timestamp: 1651238216\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00002\n",
      "  warmup_time: 0.003976583480834961\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-04-29 13:17:02 (running for 00:00:27.19)\n",
      "Memory usage on this node: 42.1/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: -0.5840206146240234\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (6 PENDING, 4 RUNNING)\n",
      "+-------------------+----------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "| Trial name        | status   | loc             |   batch_size |   hidden_size |    lr |     loss |   accuracy |   training_iteration |\n",
      "|-------------------+----------+-----------------+--------------+---------------+-------+----------+------------+----------------------|\n",
      "| train_980e3_00000 | RUNNING  | 10.1.0.103:501  |           50 |           350 | 1e-05 |          |            |                      |\n",
      "| train_980e3_00001 | RUNNING  | 10.1.0.103:536  |           10 |           350 | 0.001 |          |            |                      |\n",
      "| train_980e3_00002 | RUNNING  | 10.1.0.103:798  |           50 |           500 | 1e-05 | 0.584021 |       0.66 |                    1 |\n",
      "| train_980e3_00003 | RUNNING  | 10.1.0.103:1074 |           50 |           350 | 0.001 |          |            |                      |\n",
      "| train_980e3_00004 | PENDING  |                 |           10 |           350 | 0.1   |          |            |                      |\n",
      "| train_980e3_00005 | PENDING  |                 |           50 |           500 | 1e-05 |          |            |                      |\n",
      "| train_980e3_00006 | PENDING  |                 |          100 |           350 | 0.001 |          |            |                      |\n",
      "| train_980e3_00007 | PENDING  |                 |          100 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00008 | PENDING  |                 |           10 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00009 | PENDING  |                 |          100 |           350 | 1e-05 |          |            |                      |\n",
      "+-------------------+----------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_980e3_00001:\n",
      "  accuracy: 0.25\n",
      "  date: 2022-04-29_13-16-50\n",
      "  done: true\n",
      "  experiment_id: d823d99154d94736b74c8e4bc9292c08\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.9777649402618408\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 536\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.1734881401062012\n",
      "  time_this_iter_s: 1.1734881401062012\n",
      "  time_total_s: 1.1734881401062012\n",
      "  timestamp: 1651238210\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00001\n",
      "  warmup_time: 0.004151582717895508\n",
      "  \n",
      "Result for train_980e3_00000:\n",
      "  accuracy: 0.45\n",
      "  date: 2022-04-29_13-16-43\n",
      "  done: true\n",
      "  experiment_id: 77799b2a7fb6440d9b72c3f1205839e2\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.8479202687740326\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 501\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.5823047161102295\n",
      "  time_this_iter_s: 0.5823047161102295\n",
      "  time_total_s: 0.5823047161102295\n",
      "  timestamp: 1651238203\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00000\n",
      "  warmup_time: 0.0045125484466552734\n",
      "  \n",
      "Result for train_980e3_00003:\n",
      "  accuracy: 0.71\n",
      "  date: 2022-04-29_13-17-02\n",
      "  done: false\n",
      "  experiment_id: cc580c4558004c7f9061e4fa61626e0f\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.5843560099601746\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 1074\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6664705276489258\n",
      "  time_this_iter_s: 0.6664705276489258\n",
      "  time_total_s: 0.6664705276489258\n",
      "  timestamp: 1651238222\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00003\n",
      "  warmup_time: 0.004043102264404297\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:17:03,179\tINFO trial_runner.py:803 -- starting train_980e3_00004\n",
      "2022-04-29 13:17:03,240\tINFO trial_runner.py:803 -- starting train_980e3_00005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_980e3_00003:\n",
      "  accuracy: 0.66\n",
      "  date: 2022-04-29_13-17-03\n",
      "  done: true\n",
      "  experiment_id: cc580c4558004c7f9061e4fa61626e0f\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6033749580383301\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 1074\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.3377048969268799\n",
      "  time_this_iter_s: 0.6712343692779541\n",
      "  time_total_s: 1.3377048969268799\n",
      "  timestamp: 1651238223\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 980e3_00003\n",
      "  warmup_time: 0.004043102264404297\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:17:05,180\tINFO trial_runner.py:803 -- starting train_980e3_00006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_980e3_00002:\n",
      "  accuracy: 0.62\n",
      "  date: 2022-04-29_13-17-07\n",
      "  done: false\n",
      "  experiment_id: 92e1accef7de4c249b38d5b360832e38\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 9\n",
      "  loss: 0.643066942691803\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 798\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 11.937806844711304\n",
      "  time_this_iter_s: 0.6363670825958252\n",
      "  time_total_s: 11.937806844711304\n",
      "  timestamp: 1651238227\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 9\n",
      "  trial_id: 980e3_00002\n",
      "  warmup_time: 0.003976583480834961\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-04-29 13:17:07 (running for 00:00:32.56)\n",
      "Memory usage on this node: 41.2/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=3\n",
      "Bracket: Iter 8.000: -0.6599599421024323 | Iter 4.000: -0.49694211781024933 | Iter 2.000: -0.6014381051063538 | Iter 1.000: -0.7161381393671036\n",
      "Resources requested: 8.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (3 PENDING, 4 RUNNING, 3 TERMINATED)\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "| Trial name        | status     | loc             |   batch_size |   hidden_size |    lr |     loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------|\n",
      "| train_980e3_00002 | RUNNING    | 10.1.0.103:798  |           50 |           500 | 1e-05 | 0.643067 |       0.62 |                    9 |\n",
      "| train_980e3_00004 | RUNNING    | 10.1.0.103:2037 |           10 |           350 | 0.1   |          |            |                      |\n",
      "| train_980e3_00005 | RUNNING    | 10.1.0.103:2038 |           50 |           500 | 1e-05 |          |            |                      |\n",
      "| train_980e3_00006 | RUNNING    | 10.1.0.103:2849 |          100 |           350 | 0.001 |          |            |                      |\n",
      "| train_980e3_00007 | PENDING    |                 |          100 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00008 | PENDING    |                 |           10 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00009 | PENDING    |                 |          100 |           350 | 1e-05 |          |            |                      |\n",
      "| train_980e3_00000 | TERMINATED | 10.1.0.103:501  |           50 |           350 | 1e-05 | 0.84792  |       0.45 |                    1 |\n",
      "| train_980e3_00001 | TERMINATED | 10.1.0.103:536  |           10 |           350 | 0.001 | 0.977765 |       0.25 |                    1 |\n",
      "| train_980e3_00003 | TERMINATED | 10.1.0.103:1074 |           50 |           350 | 0.001 | 0.603375 |       0.66 |                    2 |\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_980e3_00005:\n",
      "  accuracy: 0.62\n",
      "  date: 2022-04-29_13-17-11\n",
      "  done: false\n",
      "  experiment_id: b520b0e085574a5bb64589cbef1c8d5b\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6342948973178864\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 2038\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.7230825424194336\n",
      "  time_this_iter_s: 0.7230825424194336\n",
      "  time_total_s: 0.7230825424194336\n",
      "  timestamp: 1651238231\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00005\n",
      "  warmup_time: 0.0055387020111083984\n",
      "  \n",
      "Result for train_980e3_00004:\n",
      "  accuracy: 0.54\n",
      "  date: 2022-04-29_13-17-11\n",
      "  done: true\n",
      "  experiment_id: 632f7240bdf944f59b9ee764dac64983\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.7083814144134521\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 2037\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.2681362628936768\n",
      "  time_this_iter_s: 1.2681362628936768\n",
      "  time_total_s: 1.2681362628936768\n",
      "  timestamp: 1651238231\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00004\n",
      "  warmup_time: 0.004951953887939453\n",
      "  \n",
      "Result for train_980e3_00006:\n",
      "  accuracy: 0.56\n",
      "  date: 2022-04-29_13-17-12\n",
      "  done: true\n",
      "  experiment_id: aeb6a11ff8924017a501c5570637f95d\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.7322486042976379\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 2849\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6566746234893799\n",
      "  time_this_iter_s: 0.6566746234893799\n",
      "  time_total_s: 0.6566746234893799\n",
      "  timestamp: 1651238232\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00006\n",
      "  warmup_time: 0.004362583160400391\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-04-29 13:17:12 (running for 00:00:37.85)\n",
      "Memory usage on this node: 41.8/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=5\n",
      "Bracket: Iter 8.000: -0.6599599421024323 | Iter 4.000: -0.49694211781024933 | Iter 2.000: -0.6014381051063538 | Iter 1.000: -0.7083814144134521\n",
      "Resources requested: 6.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (3 PENDING, 3 RUNNING, 4 TERMINATED)\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "| Trial name        | status     | loc             |   batch_size |   hidden_size |    lr |     loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------|\n",
      "| train_980e3_00002 | RUNNING    | 10.1.0.103:798  |           50 |           500 | 1e-05 | 0.643067 |       0.62 |                    9 |\n",
      "| train_980e3_00005 | RUNNING    | 10.1.0.103:2038 |           50 |           500 | 1e-05 | 0.634295 |       0.62 |                    1 |\n",
      "| train_980e3_00006 | RUNNING    | 10.1.0.103:2849 |          100 |           350 | 0.001 | 0.732249 |       0.56 |                    1 |\n",
      "| train_980e3_00007 | PENDING    |                 |          100 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00008 | PENDING    |                 |           10 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00009 | PENDING    |                 |          100 |           350 | 1e-05 |          |            |                      |\n",
      "| train_980e3_00000 | TERMINATED | 10.1.0.103:501  |           50 |           350 | 1e-05 | 0.84792  |       0.45 |                    1 |\n",
      "| train_980e3_00001 | TERMINATED | 10.1.0.103:536  |           10 |           350 | 0.001 | 0.977765 |       0.25 |                    1 |\n",
      "| train_980e3_00003 | TERMINATED | 10.1.0.103:1074 |           50 |           350 | 0.001 | 0.603375 |       0.66 |                    2 |\n",
      "| train_980e3_00004 | TERMINATED | 10.1.0.103:2037 |           10 |           350 | 0.1   | 0.708381 |       0.54 |                    1 |\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:17:13,181\tINFO trial_runner.py:803 -- starting train_980e3_00007\n",
      "2022-04-29 13:17:13,226\tINFO trial_runner.py:803 -- starting train_980e3_00008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for train_980e3_00005:\n",
      "  accuracy: 0.64\n",
      "  date: 2022-04-29_13-17-13\n",
      "  done: true\n",
      "  experiment_id: b520b0e085574a5bb64589cbef1c8d5b\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6022040545940399\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 2038\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.615435838699341\n",
      "  time_this_iter_s: 1.8923532962799072\n",
      "  time_total_s: 2.615435838699341\n",
      "  timestamp: 1651238233\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 980e3_00005\n",
      "  warmup_time: 0.0055387020111083984\n",
      "  \n",
      "Result for train_980e3_00002:\n",
      "  accuracy: 0.61\n",
      "  date: 2022-04-29_13-17-13\n",
      "  done: true\n",
      "  experiment_id: 92e1accef7de4c249b38d5b360832e38\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 10\n",
      "  loss: 0.6364166140556335\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 798\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 17.46670937538147\n",
      "  time_this_iter_s: 5.528902530670166\n",
      "  time_total_s: 17.46670937538147\n",
      "  timestamp: 1651238233\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 10\n",
      "  trial_id: 980e3_00002\n",
      "  warmup_time: 0.003976583480834961\n",
      "  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:17:15,181\tINFO trial_runner.py:803 -- starting train_980e3_00009\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2022-04-29 13:17:20 (running for 00:00:45.11)\n",
      "Memory usage on this node: 41.8/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=7\n",
      "Bracket: Iter 8.000: -0.6599599421024323 | Iter 4.000: -0.49694211781024933 | Iter 2.000: -0.6022040545940399 | Iter 1.000: -0.7083814144134521\n",
      "Resources requested: 6.0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (3 RUNNING, 7 TERMINATED)\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "| Trial name        | status     | loc             |   batch_size |   hidden_size |    lr |     loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------|\n",
      "| train_980e3_00007 | RUNNING    | 10.1.0.103:4888 |          100 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00008 | RUNNING    | 10.1.0.103:4890 |           10 |           200 | 0.1   |          |            |                      |\n",
      "| train_980e3_00009 | RUNNING    | 10.1.0.103:4900 |          100 |           350 | 1e-05 |          |            |                      |\n",
      "| train_980e3_00000 | TERMINATED | 10.1.0.103:501  |           50 |           350 | 1e-05 | 0.84792  |       0.45 |                    1 |\n",
      "| train_980e3_00001 | TERMINATED | 10.1.0.103:536  |           10 |           350 | 0.001 | 0.977765 |       0.25 |                    1 |\n",
      "| train_980e3_00002 | TERMINATED | 10.1.0.103:798  |           50 |           500 | 1e-05 | 0.636417 |       0.61 |                   10 |\n",
      "| train_980e3_00003 | TERMINATED | 10.1.0.103:1074 |           50 |           350 | 0.001 | 0.603375 |       0.66 |                    2 |\n",
      "| train_980e3_00004 | TERMINATED | 10.1.0.103:2037 |           10 |           350 | 0.1   | 0.708381 |       0.54 |                    1 |\n",
      "| train_980e3_00005 | TERMINATED | 10.1.0.103:2038 |           50 |           500 | 1e-05 | 0.602204 |       0.64 |                    2 |\n",
      "| train_980e3_00006 | TERMINATED | 10.1.0.103:2849 |          100 |           350 | 0.001 | 0.732249 |       0.56 |                    1 |\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "\n",
      "\n",
      "Result for train_980e3_00008:\n",
      "  accuracy: 0.49\n",
      "  date: 2022-04-29_13-17-20\n",
      "  done: true\n",
      "  experiment_id: 5df356fa5ac94e5e87aef5f81320c612\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.7159784376621247\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 4890\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 1.0114398002624512\n",
      "  time_this_iter_s: 1.0114398002624512\n",
      "  time_total_s: 1.0114398002624512\n",
      "  timestamp: 1651238240\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00008\n",
      "  warmup_time: 0.007197380065917969\n",
      "  \n",
      "Result for train_980e3_00007:\n",
      "  accuracy: 0.67\n",
      "  date: 2022-04-29_13-17-20\n",
      "  done: false\n",
      "  experiment_id: 9eb88900c0b14d9cbde04d7a9a5f15e7\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.6131802201271057\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 4888\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.5225687026977539\n",
      "  time_this_iter_s: 0.5225687026977539\n",
      "  time_total_s: 0.5225687026977539\n",
      "  timestamp: 1651238240\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00007\n",
      "  warmup_time: 0.005237579345703125\n",
      "  \n",
      "Result for train_980e3_00007:\n",
      "  accuracy: 0.65\n",
      "  date: 2022-04-29_13-17-22\n",
      "  done: true\n",
      "  experiment_id: 9eb88900c0b14d9cbde04d7a9a5f15e7\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 2\n",
      "  loss: 0.6228410601615906\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 4888\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 2.686779022216797\n",
      "  time_this_iter_s: 2.164210319519043\n",
      "  time_total_s: 2.686779022216797\n",
      "  timestamp: 1651238242\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 2\n",
      "  trial_id: 980e3_00007\n",
      "  warmup_time: 0.005237579345703125\n",
      "  \n",
      "Result for train_980e3_00009:\n",
      "  accuracy: 0.54\n",
      "  date: 2022-04-29_13-17-22\n",
      "  done: true\n",
      "  experiment_id: 3227861bc7bc4606bb8459fb9ebad919\n",
      "  hostname: jupyter-gianluca-20colangelo\n",
      "  iterations_since_restore: 1\n",
      "  loss: 0.7670621275901794\n",
      "  node_ip: 10.1.0.103\n",
      "  pid: 4900\n",
      "  should_checkpoint: true\n",
      "  time_since_restore: 0.6245896816253662\n",
      "  time_this_iter_s: 0.6245896816253662\n",
      "  time_total_s: 0.6245896816253662\n",
      "  timestamp: 1651238242\n",
      "  timesteps_since_restore: 0\n",
      "  training_iteration: 1\n",
      "  trial_id: 980e3_00009\n",
      "  warmup_time: 0.004323720932006836\n",
      "  \n",
      "== Status ==\n",
      "Current time: 2022-04-29 13:17:22 (running for 00:00:47.50)\n",
      "Memory usage on this node: 40.9/220.2 GiB\n",
      "Using AsyncHyperBand: num_stopped=10\n",
      "Bracket: Iter 8.000: -0.6599599421024323 | Iter 4.000: -0.49694211781024933 | Iter 2.000: -0.602789506316185 | Iter 1.000: -0.7121799260377883\n",
      "Resources requested: 0/8 CPUs, 0/1 GPUs, 0.0/57.22 GiB heap, 0.0/28.52 GiB objects (0.0/1.0 accelerator_type:V100)\n",
      "Result logdir: /home/jovyan/ray_results/train_2022-04-29_13-16-35\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "| Trial name        | status     | loc             |   batch_size |   hidden_size |    lr |     loss |   accuracy |   training_iteration |\n",
      "|-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------|\n",
      "| train_980e3_00000 | TERMINATED | 10.1.0.103:501  |           50 |           350 | 1e-05 | 0.84792  |       0.45 |                    1 |\n",
      "| train_980e3_00001 | TERMINATED | 10.1.0.103:536  |           10 |           350 | 0.001 | 0.977765 |       0.25 |                    1 |\n",
      "| train_980e3_00002 | TERMINATED | 10.1.0.103:798  |           50 |           500 | 1e-05 | 0.636417 |       0.61 |                   10 |\n",
      "| train_980e3_00003 | TERMINATED | 10.1.0.103:1074 |           50 |           350 | 0.001 | 0.603375 |       0.66 |                    2 |\n",
      "| train_980e3_00004 | TERMINATED | 10.1.0.103:2037 |           10 |           350 | 0.1   | 0.708381 |       0.54 |                    1 |\n",
      "| train_980e3_00005 | TERMINATED | 10.1.0.103:2038 |           50 |           500 | 1e-05 | 0.602204 |       0.64 |                    2 |\n",
      "| train_980e3_00006 | TERMINATED | 10.1.0.103:2849 |          100 |           350 | 0.001 | 0.732249 |       0.56 |                    1 |\n",
      "| train_980e3_00007 | TERMINATED | 10.1.0.103:4888 |          100 |           200 | 0.1   | 0.622841 |       0.65 |                    2 |\n",
      "| train_980e3_00008 | TERMINATED | 10.1.0.103:4890 |           10 |           200 | 0.1   | 0.715978 |       0.49 |                    1 |\n",
      "| train_980e3_00009 | TERMINATED | 10.1.0.103:4900 |          100 |           350 | 1e-05 | 0.767062 |       0.54 |                    1 |\n",
      "+-------------------+------------+-----------------+--------------+---------------+-------+----------+------------+----------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-29 13:17:22,722\tINFO tune.py:702 -- Total run time: 47.80 seconds (47.49 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 1e-05, 'hidden_size': 500, 'batch_size': 50}\n",
      "Best trial final validation loss: 0.6022040545940399\n",
      "Best trial final validation accuracy: 0.64\n",
      "Best trial test set accuracy: 0.6387809616318602\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # You can change the number of GPUs per trial here:\n",
    "    main(num_samples=10, max_num_epochs=10, gpus_per_trial=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb213b1f-4356-42d6-9f1d-ee72076927b4",
   "metadata": {},
   "source": [
    "So according to the outcome of the tuning process the combination of learning rate = 1e-5, hidden_size = 500 and batch size = 50 is the best possible combination in this case. Of course for simplicity reasons we used only 10 trials and 10 epochs that might have to be modified but this is good enough for the scope of this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c362168-215f-4985-8e1d-00dd864d4936",
   "metadata": {},
   "source": [
    "## Training and testing of the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2963fe4-2e92-4211-96f8-798497014017",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdf455f",
   "metadata": {},
   "source": [
    "In line with the tuning process above we assign the optimal parameters. Note that in [2] the hidden size was set to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e185269",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 500\n",
    "drop_prob = 0.1\n",
    "learning_rate=1e-5\n",
    "\n",
    "model_params = {\n",
    "                'seq_length': seq_length,\n",
    "                'hidden_size' : hidden_size,\n",
    "                'n_classes' : n_classes,\n",
    "                'drop_prob' : drop_prob   \n",
    "               }\n",
    "\n",
    "model = get_model('mlp', model_params).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dad6b0",
   "metadata": {},
   "source": [
    "Structure of the model with the indication of the trainable parmeters that for MLP amount to 764K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db2807f7-07fe-47c7-b177-ff34dd2cced1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Dropout-1                 [50, 1024]               0\n",
      "            Linear-2                  [50, 500]         512,500\n",
      "              ReLU-3                  [50, 500]               0\n",
      "           Dropout-4                  [50, 500]               0\n",
      "            Linear-5                  [50, 500]         250,500\n",
      "              ReLU-6                  [50, 500]               0\n",
      "           Dropout-7                  [50, 500]               0\n",
      "            Linear-8                    [50, 3]           1,503\n",
      "              ReLU-9                    [50, 3]               0\n",
      "          Dropout-10                    [50, 3]               0\n",
      "================================================================\n",
      "Total params: 764,503\n",
      "Trainable params: 764,503\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 1.54\n",
      "Params size (MB): 2.92\n",
      "Estimated Total Size (MB): 4.65\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(1024, 1),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c9c06d-b401-4871-88ad-f5426902529a",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### MLP training cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f781657",
   "metadata": {},
   "source": [
    "The loss function we use for the whole notebook is the **cross-entropy loss**, while we take **Adam** as an optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "50274652-5530-411f-a4df-a964b0417187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Training loss: 1.0768\t Validation loss: 1.0132\n",
      "[2/100] Training loss: 0.9839\t Validation loss: 0.9061\n",
      "[3/100] Training loss: 0.8907\t Validation loss: 0.8128\n",
      "[4/100] Training loss: 0.8295\t Validation loss: 0.7386\n",
      "[5/100] Training loss: 0.7676\t Validation loss: 0.6815\n",
      "[6/100] Training loss: 0.7488\t Validation loss: 0.6374\n",
      "[7/100] Training loss: 0.7229\t Validation loss: 0.6052\n",
      "[8/100] Training loss: 0.7139\t Validation loss: 0.5803\n",
      "[9/100] Training loss: 0.7085\t Validation loss: 0.5600\n",
      "[10/100] Training loss: 0.6689\t Validation loss: 0.5416\n",
      "[50/100] Training loss: 0.6101\t Validation loss: 0.3872\n",
      "[100/100] Training loss: 0.5974\t Validation loss: 0.3632\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=seq_length)\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38753858",
   "metadata": {},
   "source": [
    "The model learns well in the first 10-20 epochs. After 20 epochs the loss flattens out both for training and validation set. Note that the validation set seems to be easier to predict than the training. The fact that the validation curve is lower than the training curve might be an indication that the validation set is not representative, not big enough and we might need to extend it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef48e34a-31c9-4034-b135-87d7325f470e",
   "metadata": {},
   "source": [
    "#### MLP performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03d72835-8111-402b-8d89-90f80b7fe841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  MLPModel(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=500, out_features=3, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout3): Dropout(p=0.30000000000000004, inplace=False)\n",
      ")  : 86.56 %\n",
      "Correct :  779 Total :  900\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(train_loader, batch_size=batch_size, n_features=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "82999e31-06f9-416d-bac4-3c3b6bc64707",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.15      0.26       138\n",
      "           1       1.00      1.00      1.00       248\n",
      "           2       0.81      0.99      0.89       514\n",
      "\n",
      "    accuracy                           0.87       900\n",
      "   macro avg       0.88      0.71      0.72       900\n",
      "weighted avg       0.87      0.87      0.83       900\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 21,   0, 117],\n",
       "       [  0, 248,   0],\n",
       "       [  4,   0, 510]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879ad865-03cb-437b-b488-0f2aa549a97e",
   "metadata": {},
   "source": [
    "#### MLP performance on testing set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "82c61a4e-f6e2-468f-bfdc-adfdcf89300e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  MLPModel(\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=500, bias=True)\n",
      "  (relu1): ReLU()\n",
      "  (dropout1): Dropout(p=0.2, inplace=False)\n",
      "  (fc2): Linear(in_features=500, out_features=500, bias=True)\n",
      "  (relu2): ReLU()\n",
      "  (dropout2): Dropout(p=0.2, inplace=False)\n",
      "  (fc3): Linear(in_features=500, out_features=3, bias=True)\n",
      "  (relu3): ReLU()\n",
      "  (dropout3): Dropout(p=0.30000000000000004, inplace=False)\n",
      ")  : 86.44 %\n",
      "Correct :  7088 Total :  8200\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(test_loader, batch_size=batch_size, n_features=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e93434f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.11      0.19      1172\n",
      "           1       1.00      1.00      1.00      2295\n",
      "           2       0.82      0.98      0.89      4733\n",
      "\n",
      "    accuracy                           0.86      8200\n",
      "   macro avg       0.82      0.70      0.70      8200\n",
      "weighted avg       0.85      0.86      0.82      8200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 133,    2, 1037],\n",
       "       [   0, 2293,    2],\n",
       "       [  69,    2, 4662]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784a6652",
   "metadata": {},
   "source": [
    "Looking at the very close accuracy measured on the training and testing sets we can say that we are certainly not overfitting.\n",
    "\n",
    "Note that one of the class (1) is very clearly separable from the others while the other are easily mixed up. In particular, class 0 shows the poorer precision and recall performance, being easily confused with class 2.\n",
    "\n",
    "Finally comparing the performance of our model with the one documented in [2] in which Adadelta, an adaptive learning rate method, is used as an optimizer, we actually see that our error rate is ~ 7% higher. This means that indeed we have room to improve our model. Without changing the optimizer we could review our hyper-parameters tuning process and choose a better combination of the parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d5ead-8512-48df-ad76-695d4af92130",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fe8b39",
   "metadata": {},
   "source": [
    "LSTM-specific parameter definition. We decide to set the hidden size of LSTM to 128."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4c87a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "n_layers = 1\n",
    "drop_prob = 0\n",
    "\n",
    "model_params = {'input_size': input_size,\n",
    "                'hidden_size' : hidden_size,\n",
    "                'n_layers' : n_layers,\n",
    "                'n_classes' : n_classes,\n",
    "                'drop_prob' : drop_prob}\n",
    "\n",
    "model = get_model('lstm', model_params).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a321895d-1cfb-4d7b-b853-23ca0dbb3e31",
   "metadata": {},
   "source": [
    "#### LSTM training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c14bdb9-5dfc-44ee-ba5c-2c0b18635dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters for our LSTM model :  67459\n"
     ]
    }
   ],
   "source": [
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "params = sum([np.prod(p.size()) for p in model_parameters])\n",
    "print (\"Number of trainable parameters for our LSTM model : \", params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7116ba59-a8eb-4d93-9df5-4ece53b398e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Training loss: 1.0729\t Validation loss: 1.0699\n",
      "[2/100] Training loss: 1.0713\t Validation loss: 1.0682\n",
      "[3/100] Training loss: 1.0696\t Validation loss: 1.0664\n",
      "[4/100] Training loss: 1.0679\t Validation loss: 1.0647\n",
      "[5/100] Training loss: 1.0663\t Validation loss: 1.0629\n",
      "[6/100] Training loss: 1.0646\t Validation loss: 1.0612\n",
      "[7/100] Training loss: 1.0630\t Validation loss: 1.0594\n",
      "[8/100] Training loss: 1.0613\t Validation loss: 1.0577\n",
      "[9/100] Training loss: 1.0597\t Validation loss: 1.0559\n",
      "[10/100] Training loss: 1.0580\t Validation loss: 1.0542\n",
      "[50/100] Training loss: 0.7804\t Validation loss: 0.7590\n",
      "[100/100] Training loss: 0.5890\t Validation loss: 0.5564\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "#loss_fn = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_size)\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a05188",
   "metadata": {},
   "source": [
    "The shape of the loss curve is quite interesting. What we see in fact is that in the first 40 epochs the learning is extremely slow. After that the loss drops suddenly and keeps on dropping at a good rate even at later epochs.\n",
    "\n",
    "The model has not learned enough and it is probably underfitting. Probably the learning process stopped prematurely. We conclude that it would certainly benefit from a higher learning rate or an increased number of epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc678937-b8d8-44ca-8c24-deed77ac3e0d",
   "metadata": {},
   "source": [
    "#### LSTM performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9715472-a67b-436d-9bea-05581ae4cbd3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  LSTMModel(\n",
      "  (lstm): LSTM(1, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")  : 79.56 %\n",
      "Correct :  716 Total :  900\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(train_loader, batch_size=batch_size, n_features=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "072a0c11-4634-4cd1-8652-e4f8e62a7b4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       138\n",
      "           1       0.81      0.98      0.89       248\n",
      "           2       0.79      0.92      0.85       514\n",
      "\n",
      "    accuracy                           0.80       900\n",
      "   macro avg       0.53      0.63      0.58       900\n",
      "weighted avg       0.67      0.80      0.73       900\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  0,  16, 122],\n",
       "       [  0, 243,   5],\n",
       "       [  0,  41, 473]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c7155f-f53f-43c0-bfc3-01c820f87920",
   "metadata": {},
   "source": [
    "#### LSTM performance on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45985dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  LSTMModel(\n",
      "  (lstm): LSTM(1, 128, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      ")  : 80.74 %\n",
      "Correct :  6621 Total :  8200\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(test_loader, batch_size=batch_size, n_features=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ce09640-c1dd-4089-91c7-3560f54fa405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1172\n",
      "           1       0.81      0.98      0.89      2295\n",
      "           2       0.81      0.92      0.86      4733\n",
      "\n",
      "    accuracy                           0.81      8200\n",
      "   macro avg       0.54      0.63      0.58      8200\n",
      "weighted avg       0.69      0.81      0.75      8200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,  173,  999],\n",
       "       [   0, 2253,   42],\n",
       "       [   0,  365, 4368]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e8563",
   "metadata": {},
   "source": [
    "The accuracy on the testing set is similar to the one on the training set actually even slightly higher. What is strange is that the model is not able to detect class 0 at all. If we applied a Softmax layer on the model output then class 0 would be detected but strangely enough accuracy would drop by 10%. For the fact previously mentioned that CrossEntropyLoss already implies a SoftMax calculation, we actually decided to remove that layer.\n",
    "\n",
    "Also here a tuning of the hyper-parameters used would be required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aeb0113-87a4-4bfd-b739-c84b101711f8",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf24fcb5",
   "metadata": {},
   "source": [
    "CNN-specific parameter setting. In comparison to what was recommended in [1] we increased the number of filters from (6, 12) to (32, 64). With (6, 12) like in the LSTM case, class 0 is not detected. Increasing the number of filters improved the class-0 detection capabilities.\n",
    "\n",
    "Number of filters would be an excellent parameter to give as an input to Ray Tuner. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "29352f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_filters = 32\n",
    "conv_filters2 = 64\n",
    "conv_filter_size = 7\n",
    "num_units_fc = 50\n",
    "\n",
    "drop_prob = 0\n",
    "\n",
    "model_params = {\n",
    "    'conv_filters': conv_filters,\n",
    "    'conv_filters2' : conv_filters2,\n",
    "    'conv_filter_size' : conv_filter_size,\n",
    "    'num_units_fc' : num_units_fc\n",
    "}\n",
    "\n",
    "model = get_model('cnn', model_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "358bee1f-e276-48fc-a9a8-1515394cf0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [50, 32, 1018]             256\n",
      "         MaxPool1d-2              [50, 32, 509]               0\n",
      "            Conv1d-3              [50, 64, 503]          14,400\n",
      "         MaxPool1d-4              [50, 64, 251]               0\n",
      "            Linear-5                   [50, 50]         803,250\n",
      "            Linear-6                    [50, 3]             153\n",
      "================================================================\n",
      "Total params: 818,059\n",
      "Trainable params: 818,059\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 37.07\n",
      "Params size (MB): 3.12\n",
      "Estimated Total Size (MB): 40.38\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(1024, 1),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656e10de-c996-4337-921a-64dc15c1efc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### CNN training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f83ac9e4-3a0f-4f5e-a13a-da388045051d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Training loss: 0.9800\t Validation loss: 0.8534\n",
      "[2/100] Training loss: 0.7554\t Validation loss: 0.6505\n",
      "[3/100] Training loss: 0.5885\t Validation loss: 0.5277\n",
      "[4/100] Training loss: 0.4873\t Validation loss: 0.4560\n",
      "[5/100] Training loss: 0.4271\t Validation loss: 0.4165\n",
      "[6/100] Training loss: 0.3935\t Validation loss: 0.3923\n",
      "[7/100] Training loss: 0.3728\t Validation loss: 0.3758\n",
      "[8/100] Training loss: 0.3591\t Validation loss: 0.3641\n",
      "[9/100] Training loss: 0.3495\t Validation loss: 0.3555\n",
      "[10/100] Training loss: 0.3420\t Validation loss: 0.3477\n",
      "[50/100] Training loss: 0.2837\t Validation loss: 0.2783\n",
      "[100/100] Training loss: 0.2510\t Validation loss: 0.2340\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_size)\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e64154",
   "metadata": {},
   "source": [
    "In this case the loss on the training data set goes down very rapidly for about 10 epochs and then tend to flatten out even if continue a slow descent. Very similar behaviour happens on the validation set. This means that we have not reached a stage of overfitting. Actually the learning curve has almost an ideal shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64acdc59-c18d-49d4-b6be-b60be45ceec2",
   "metadata": {},
   "source": [
    "#### CNN performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ec976f3-87a2-4bd5-91a5-6d51d1e33962",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  CNNModel(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(7,), stride=(1,))\n",
      "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(7,), stride=(1,))\n",
      "  (max_pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=16064, out_features=50, bias=True)\n",
      "  (out): Linear(in_features=50, out_features=3, bias=True)\n",
      ")  : 87.67 %\n",
      "Correct :  789 Total :  900\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(train_loader, batch_size=batch_size, n_features=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6dba6e75-7042-46b3-9492-6d429c1d899f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.29      0.42       138\n",
      "           1       1.00      1.00      1.00       248\n",
      "           2       0.84      0.97      0.90       514\n",
      "\n",
      "    accuracy                           0.88       900\n",
      "   macro avg       0.86      0.75      0.77       900\n",
      "weighted avg       0.87      0.88      0.85       900\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 40,   0,  98],\n",
       "       [  0, 248,   0],\n",
       "       [ 13,   0, 501]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3627f04-a65f-4834-86db-15166aa19087",
   "metadata": {},
   "source": [
    "#### CNN performance on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "99523f18-d54e-40c6-9da4-e1e324007d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  CNNModel(\n",
      "  (conv1): Conv1d(1, 32, kernel_size=(7,), stride=(1,))\n",
      "  (max_pool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv1d(32, 64, kernel_size=(7,), stride=(1,))\n",
      "  (max_pool2): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc): Linear(in_features=16064, out_features=50, bias=True)\n",
      "  (out): Linear(in_features=50, out_features=3, bias=True)\n",
      ")  : 86.06 %\n",
      "Correct :  7057 Total :  8200\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(test_loader, batch_size=batch_size, n_features=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0eb1b453-e21f-4d04-b351-dc211d06bd5b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.20      0.30      1172\n",
      "           1       0.99      1.00      1.00      2295\n",
      "           2       0.83      0.96      0.89      4733\n",
      "\n",
      "    accuracy                           0.86      8200\n",
      "   macro avg       0.79      0.72      0.73      8200\n",
      "weighted avg       0.84      0.86      0.83      8200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 239,    3,  930],\n",
       "       [   2, 2290,    3],\n",
       "       [ 196,    9, 4528]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93c60fa",
   "metadata": {},
   "source": [
    "The performance on the testing set is only 1% lower than on the training set. Increasing the number of filters would probably improve further the accuracy of the model and also the ability to detect more precisely class 0 (precision and recall). Again something to be tuned with the help of Ray Tuner."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e993ee-6fea-4410-b98b-277b61919cbe",
   "metadata": {},
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61aaffb",
   "metadata": {},
   "source": [
    "ResNet-specific parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3a5a44a-bf36-4421-8e3b-7976a674fca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResBlock(\n",
      "  (convblock1): Sequential(\n",
      "    (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convblock2): Sequential(\n",
      "    (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (convblock3): Sequential(\n",
      "    (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (shortcut): Sequential()\n",
      "  (act): ReLU()\n",
      ")\n",
      "AdaptiveAvgPool1d(output_size=1)\n",
      "Linear(in_features=128, out_features=3, bias=True)\n"
     ]
    }
   ],
   "source": [
    "conv_filters=64\n",
    "drop_prob = 0\n",
    "\n",
    "model_params = {'in_channels': input_size,\n",
    "                'mid_channels' : conv_filters,\n",
    "                'num_pred_classes' : n_classes\n",
    "               }\n",
    "\n",
    "model = get_model('resnet', model_params).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "edb7fadd-28ac-46e9-ab19-7f8c2d845533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv1d-1             [50, 64, 1024]             512\n",
      "       BatchNorm1d-2             [50, 64, 1024]             128\n",
      "              ReLU-3             [50, 64, 1024]               0\n",
      "            Conv1d-4             [50, 64, 1024]          20,544\n",
      "       BatchNorm1d-5             [50, 64, 1024]             128\n",
      "              ReLU-6             [50, 64, 1024]               0\n",
      "            Conv1d-7             [50, 64, 1024]          12,352\n",
      "       BatchNorm1d-8             [50, 64, 1024]             128\n",
      "              ReLU-9             [50, 64, 1024]               0\n",
      "           Conv1d-10             [50, 64, 1024]             128\n",
      "      BatchNorm1d-11             [50, 64, 1024]             128\n",
      "             ReLU-12             [50, 64, 1024]               0\n",
      "         ResBlock-13             [50, 64, 1024]               0\n",
      "           Conv1d-14            [50, 128, 1024]          57,472\n",
      "      BatchNorm1d-15            [50, 128, 1024]             256\n",
      "             ReLU-16            [50, 128, 1024]               0\n",
      "           Conv1d-17            [50, 128, 1024]          82,048\n",
      "      BatchNorm1d-18            [50, 128, 1024]             256\n",
      "             ReLU-19            [50, 128, 1024]               0\n",
      "           Conv1d-20            [50, 128, 1024]          49,280\n",
      "      BatchNorm1d-21            [50, 128, 1024]             256\n",
      "             ReLU-22            [50, 128, 1024]               0\n",
      "           Conv1d-23            [50, 128, 1024]           8,320\n",
      "      BatchNorm1d-24            [50, 128, 1024]             256\n",
      "             ReLU-25            [50, 128, 1024]               0\n",
      "         ResBlock-26            [50, 128, 1024]               0\n",
      "           Conv1d-27            [50, 128, 1024]         114,816\n",
      "      BatchNorm1d-28            [50, 128, 1024]             256\n",
      "             ReLU-29            [50, 128, 1024]               0\n",
      "           Conv1d-30            [50, 128, 1024]          82,048\n",
      "      BatchNorm1d-31            [50, 128, 1024]             256\n",
      "             ReLU-32            [50, 128, 1024]               0\n",
      "           Conv1d-33            [50, 128, 1024]          49,280\n",
      "      BatchNorm1d-34            [50, 128, 1024]             256\n",
      "             ReLU-35            [50, 128, 1024]               0\n",
      "             ReLU-36            [50, 128, 1024]               0\n",
      "         ResBlock-37            [50, 128, 1024]               0\n",
      "AdaptiveAvgPool1d-38               [50, 128, 1]               0\n",
      "           Linear-39                    [50, 3]             387\n",
      "================================================================\n",
      "Total params: 479,491\n",
      "Trainable params: 479,491\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.20\n",
      "Forward/backward pass size (MB): 1525.05\n",
      "Params size (MB): 1.83\n",
      "Estimated Total Size (MB): 1527.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model,input_size=(1024, 1),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f98b241-97c8-433a-9b1f-c6ad76c49029",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### ResNet training cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "263d8df2-3b29-4979-8acd-f3b4be920eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/100] Training loss: 0.8791\t Validation loss: 1.0000\n",
      "[2/100] Training loss: 0.6803\t Validation loss: 0.7728\n",
      "[3/100] Training loss: 0.5899\t Validation loss: 0.5826\n",
      "[4/100] Training loss: 0.5369\t Validation loss: 0.5035\n",
      "[5/100] Training loss: 0.5020\t Validation loss: 0.4578\n",
      "[6/100] Training loss: 0.4766\t Validation loss: 0.4322\n",
      "[7/100] Training loss: 0.4563\t Validation loss: 0.4162\n",
      "[8/100] Training loss: 0.4386\t Validation loss: 0.4022\n",
      "[9/100] Training loss: 0.4215\t Validation loss: 0.3889\n",
      "[10/100] Training loss: 0.4046\t Validation loss: 0.3750\n",
      "[50/100] Training loss: 0.1936\t Validation loss: 0.1477\n",
      "[100/100] Training loss: 0.1282\t Validation loss: 0.1042\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
    "\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, n_features=input_size)\n",
    "opt.plot_losses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b240813",
   "metadata": {},
   "source": [
    "The loss curve show an excellent decreasing shape for all the epochs on both the training and validation set. Only towards the last epochs the validation curve small signs of swinging. This shows that we have probably learned everything we could."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846f90d-ac8f-4890-99b3-b0ce0fe9752f",
   "metadata": {},
   "source": [
    "#### ResNet performance on training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d94ca8a7-b66a-4a46-8fd3-cb2b80e56295",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  ResNetModel(\n",
      "  (resblock1): ResBlock(\n",
      "    (convblock1): Sequential(\n",
      "      (0): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock2): Sequential(\n",
      "      (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock3): Sequential(\n",
      "      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv1d(1, 64, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (resblock2): ResBlock(\n",
      "    (convblock1): Sequential(\n",
      "      (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock2): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock3): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (resblock3): ResBlock(\n",
      "    (convblock1): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock2): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock3): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")  : 96.89 %\n",
      "Correct :  872 Total :  900\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(train_loader, batch_size=batch_size, n_features=seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5899d2c3-d144-4e01-8f41-cd7b6c50c88b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89       138\n",
      "           1       1.00      1.00      1.00       248\n",
      "           2       0.95      1.00      0.97       514\n",
      "\n",
      "    accuracy                           0.97       900\n",
      "   macro avg       0.98      0.93      0.95       900\n",
      "weighted avg       0.97      0.97      0.97       900\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[111,   0,  27],\n",
       "       [  0, 247,   1],\n",
       "       [  0,   0, 514]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e5532-bf2b-4d14-b909-0480a23aaa4f",
   "metadata": {},
   "source": [
    "#### ResNet performance on testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9bf24f68-4c6a-4b76-8606-475950a4c4b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  ResNetModel(\n",
      "  (resblock1): ResBlock(\n",
      "    (convblock1): Sequential(\n",
      "      (0): Conv1d(1, 64, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock2): Sequential(\n",
      "      (0): Conv1d(64, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock3): Sequential(\n",
      "      (0): Conv1d(64, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv1d(1, 64, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (resblock2): ResBlock(\n",
      "    (convblock1): Sequential(\n",
      "      (0): Conv1d(64, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock2): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock3): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (shortcut): Sequential(\n",
      "      (0): Conv1d(64, 128, kernel_size=(1,), stride=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (resblock3): ResBlock(\n",
      "    (convblock1): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock2): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (convblock3): Sequential(\n",
      "      (0): Conv1d(128, 128, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "      (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (shortcut): Sequential()\n",
      "    (act): ReLU()\n",
      "  )\n",
      "  (gap): AdaptiveAvgPool1d(output_size=1)\n",
      "  (fc): Linear(in_features=128, out_features=3, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")  : 96.50 %\n",
      "Correct :  7913 Total :  8200\n"
     ]
    }
   ],
   "source": [
    "predictions, values = opt.evaluate(test_loader, batch_size=batch_size, n_features=input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3ba2515-a9b5-40ed-966f-10b336ba53c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.79      0.88      1172\n",
      "           1       1.00      0.99      0.99      2295\n",
      "           2       0.95      1.00      0.97      4733\n",
      "\n",
      "    accuracy                           0.96      8200\n",
      "   macro avg       0.98      0.92      0.95      8200\n",
      "weighted avg       0.97      0.96      0.96      8200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 921,    0,  251],\n",
       "       [   0, 2273,   22],\n",
       "       [  12,    2, 4719]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(classification_report(np.concatenate(values).ravel(), np.concatenate(predictions).ravel()))\n",
    "confusion_matrix(np.concatenate(values).ravel(), np.concatenate(predictions).ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0466984d",
   "metadata": {},
   "source": [
    "The performance of the ResNet is actually the best among the 4 models and almost in line with the measurements described in [2]. No big difference between the training and testing performance meaning that overfit did not really hit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf68650c",
   "metadata": {},
   "source": [
    "## Final considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90c6e9d",
   "metadata": {},
   "source": [
    "Below a summary of the accuracy results of the 4 models together with the number of trainable parameters that give an indication of the complexity of the model.\n",
    "\n",
    "| Model | Trainable params | Accuracy on testing set |\n",
    "| --- | --- | --- |\n",
    "| MLP | 764'503 | 86.4% |\n",
    "| LSTM | 67'459 | 80.7% |\n",
    "| CNN | 818'059 | 86.0% |\n",
    "| ResNet | 479'491 | 96.5% |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d6bf22",
   "metadata": {},
   "source": [
    "Single-layer LSTM is the simplest model in terms of number of trainable parameters and gives the lowest performance among the four. In the loss curve we see signs of underfitting. For this reason the training process should be adjusted and improved. In any case, we have verified that even increasing hidden size or the number of layers, the performance does not increase significantly. The reason why class 0 is not detected should be further investigated. Also the attention mechanism would be something interesting to implement and test. While a standard LSTM model uses the last hidden state to produce a prediction, implementing the attention mechanisms implies to use also intermediate states that could possibly improve the prediction. \n",
    "\n",
    "CNN and MLP are pretty much on par in terms of performance and complexity. Increasing the number of filters in CNN would improve significantly the performance. This reflects the CNN ability to mine and generate features automatically. By looking at the MLP loss curve it turns out that the validation set is not well representative of the validation process and should therefore be changed or increased. \n",
    "\n",
    "ResNet shows to be the best model for this type of task with excellent accuracy but also significant better ability to identify class 0 and separate it from class 2.\n",
    "\n",
    "Overall, while the hyper-parameters tuning process was set up as an example for the MLP case, it should actually be extended to the other cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cf8f6e",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac6e801",
   "metadata": {},
   "source": [
    "[1] B. Zhao, H. Lu, S. Chen, J. Liu, and D. Wu, â€œConvolutional neural networks for time series classification,â€\n",
    "Journal of Systems Engineering and Electronics, vol. 28, no. 1, pp. 162â€“169, 2017.\n",
    "\n",
    "[2] Z. Wang, W. Yan, and T. Oates, â€œTime series classification from scratch with deep neural networks:\n",
    "A strong baseline,â€ Proc. Int. Jt. Conf. Neural Networks, vol. 2017-May, pp. 1578â€“1585, 2017."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc-autonumbering": true,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
